{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requiered libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import Resizing\n",
    "from tensorflow.keras.layers import RandomFlip\n",
    "from tensorflow.keras.layers import RandomZoom\n",
    "from tensorflow.keras.layers import RandomRotation\n",
    "from tensorflow.keras.layers import RandomBrightness\n",
    "from tensorflow.keras.layers import RandomContrast \n",
    "from tensorflow.keras.layers import RandomTranslation\n",
    "\n",
    "# For evaluating performance\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Tensorboard\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "\n",
    "\n",
    "DATE= date.today().strftime(\"%Y_%m_%d\")\n",
    "DATASET_PATH_train = r\"C:\\Users\\Alex\\Documents\\GitHub\\may25_bds_plants\\05_data\\original_data\\2.1.1 New Plant Diseases\\train\"\n",
    "\n",
    "DATASET_PATH_valid = r\"C:\\Users\\Alex\\Documents\\GitHub\\may25_bds_plants\\05_data\\original_data\\2.1.1 New Plant Diseases\\valid\"\n",
    "\n",
    "#Constant variables\n",
    "\n",
    "IMAGE_SIZE = (128,128, 3)  # (height, width, channels)\n",
    "vector_size_1D = IMAGE_SIZE[0] * IMAGE_SIZE[1] * IMAGE_SIZE[2]  # Flattened size for each image\n",
    "batch_size = 64\n",
    "\n",
    "train = image_dataset_from_directory(\n",
    "    DATASET_PATH_train,  # Path to the dataset\n",
    "    labels='inferred',  # Automatically infer labels from subdirectory names\n",
    "    #label_mode='categorical',  # Use categorical labels\n",
    "    image_size=IMAGE_SIZE[:2],  # Resize images to the specified size\n",
    "    batch_size=batch_size,  # Number of images per batch\n",
    "    seed=42,  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "class_names = train.class_names #Saves all class names in a list \n",
    "classes_healthy = [class_name for class_name in train.class_names if \"healthy\" in class_name.lower()]\n",
    "classes_sick = [class_name for class_name in train.class_names if \"healthy\" not in class_name.lower()]\n",
    "\n",
    "# Validation dataset\n",
    "valid = image_dataset_from_directory(\n",
    "    DATASET_PATH_valid,  # Path to the dataset\n",
    "    labels='inferred',  # Automatically infer labels from subdirectory names\n",
    "    #label_mode='categorical',  # Use categorical labels\n",
    "    image_size=IMAGE_SIZE[:2],  # Resize images to the specified size\n",
    "    batch_size=batch_size,  # Number of images per batch\n",
    "    seed=42,  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "dataset = train #Choose the dataset to work with, e.g., train, valid, test_healthy, test_sick\n",
    "dataset_valid = valid #Choose the dataset to work with, e.g., train, valid, test_healthy, test_sick\n",
    "dataset.class_names = sorted(dataset.class_names)  # Sort class names for consistency\n",
    "\n",
    "# Configuration for performance optimization\n",
    "# This is used to optimize the performance of data loading and preprocessing\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# Apply performance optimizations to the datasets\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_valid = dataset_valid.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the model\n",
    "\n",
    "#model_path = r\"C:\\Users\\Alex\\Documents\\GitHub\\may25_bds_plants\\05_data\\models\\model_2025_07_29.keras\"\n",
    "model_path = \n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac772b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation data\n",
    "#Just run\n",
    "\n",
    "def get_predictions_and_labels(dataset):\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        \n",
    "        preds = model.predict(images, verbose=0)  # Get the model's predictions\n",
    "        pred_labels.extend(np.argmax(preds, axis=-1))  # Get the predicted labels (argmax)\n",
    "\n",
    "        true_labels.extend(labels.numpy())  # Get the true labels\n",
    "\n",
    "    return np.array(true_labels), np.array(pred_labels)\n",
    "\n",
    "def generate_classification_report(y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"Normalized Confusion Matrix\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "y_true, y_pred = get_predictions_and_labels(dataset_valid)  # Get true labels and predictions from the test dataset\n",
    "\n",
    "# Display the classification report\n",
    "print(classification_report(y_true, y_pred))  # Print the classification report (precision, recall, F1-score)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(15, 15))  # Create a large figure for the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred, normalize='true')  # Compute the normalized confusion matrix\n",
    "sns.heatmap(cnf_matrix, cmap='Blues', annot=True, cbar=False, fmt=\".2f\")  # Plot the confusion matrix as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcfbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "cmatrix = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "#report_file = \"first_model_classification_results_2025_07_29.pkl\"\n",
    "report_file = \n",
    "with open(report_file, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"report\": report,\n",
    "        \"confusion_matrix\": cmatrix\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caad2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-cam file\n",
    "#just run\n",
    "#Grad-CAM: Visualizing Decisions\n",
    "\n",
    "#Selection 4 images from the validation dataset\n",
    "X = np.array([img.numpy() for img, _ in dataset_valid.take(2)][0]).astype(np.uint8)\n",
    "y = np.array([label.numpy() for _, label in dataset_valid.take(2)][0])\n",
    "\n",
    "# Select specific images\n",
    "images = X[:4]\n",
    "labels = y[:4]\n",
    "\n",
    "def grad_cam(image, model, layer_name):\n",
    "    if not any(layer.name == layer_name for layer in model.layers):\n",
    "        raise ValueError(f\"Layer {layer_name} not found in model.\")\n",
    "    # Retrieve the convolutional layer\n",
    "    layer = model.get_layer(layer_name)\n",
    "    \n",
    "    # Create a model that generates the outputs of the convolutional layer and the predictions\n",
    "    grad_model = Model(inputs=model.input, outputs=[layer.output, model.output])\n",
    "\n",
    "    # Add a batch dimension\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    # Compute the gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(image)\n",
    "        predicted_class = tf.argmax(predictions[0])  # Predicted class\n",
    "        loss = predictions[:, predicted_class]  # Loss for the predicted class\n",
    "\n",
    "    # Gradients of the scores with respect to the outputs of the convolutional layer\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "    # Weighted average of the gradients for each channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Weight the activations by the calculated gradients\n",
    "    conv_outputs = conv_outputs[0]  # Remove the batch dimension\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    # Normalize the heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0)  # Focus only on positive values\n",
    "    heatmap /= tf.math.reduce_max(heatmap) + 1e-6  # Normalize between 0 and 1\n",
    "    heatmap = heatmap.numpy()  # Convert to numpy array for visualization\n",
    "\n",
    "    # Resize the heatmap to match the original image size\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (image.shape[1], image.shape[2])).numpy()\n",
    "    heatmap_resized = np.squeeze(heatmap_resized, axis=-1)  # Remove the singleton dimension at the end of the heatmap_resized array\n",
    "\n",
    "    # Color the heatmap with a palette (e.g., \"jet\")\n",
    "    heatmap_colored = plt.cm.jet(heatmap_resized)[..., :3]  # Get the R, G, B channels \n",
    "\n",
    "    superimposed_image = heatmap_colored * 0.7 + image[0].numpy() / 255.0\n",
    "\n",
    "    return np.clip(superimposed_image, 0, 1), predicted_class\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def format_class_name(label):\n",
    "    plant, disease = label.split(\"___\")\n",
    "    return f\"{plant} ({disease.replace('_', ' ')})\"\n",
    "\n",
    "def show_grad_cam_cnn(images, labels, model, class_names, save_dir=None):\n",
    "    os.makedirs(save_dir, exist_ok=True) if save_dir else None\n",
    "\n",
    "    number_of_images = images.shape[0]\n",
    "    conv_layers = [layer.name for layer in model.layers if isinstance(layer, Conv2D)]\n",
    "    conv_layers = conv_layers[-1:]  # Use only the last convolutional layer for Grad-CAM\n",
    "    \n",
    "    plt.figure(figsize=(16,16))\n",
    "\n",
    "    for j, layer in enumerate(conv_layers):\n",
    "\n",
    "        for i in range(number_of_images):\n",
    "\n",
    "            subplot_index = i + 1 + j * number_of_images\n",
    "            plt.subplot(len(conv_layers), number_of_images, subplot_index)\n",
    "\n",
    "            # Get the image with the overlaid heatmap\n",
    "            grad_cam_image, predicted_class = grad_cam(images[i], model, layer)\n",
    "            true_label = format_class_name(class_names[labels[i]])\n",
    "            predicted_label = format_class_name(class_names[predicted_class])\n",
    "            \n",
    "            # Display the image with Grad-CAM\n",
    "            #plt.title(f'Grad-CAM {layer}')\n",
    "            plt.title(f'True: {true_label}\\nPred: {predicted_label}', fontsize=10)\n",
    "            plt.imshow(grad_cam_image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            if save_dir:\n",
    "                filename = f\"{class_names[labels[i]]}_img{i+1}.jpg\"\n",
    "                filepath = os.path.join(save_dir, filename)\n",
    "                gradcam_uint8 = (grad_cam_image * 255).astype(np.uint8)\n",
    "                Image.fromarray(gradcam_uint8).save(filepath)\n",
    "\n",
    "    if not save_dir:\n",
    "        plt.show()\n",
    "#-------------------------------------------------------------\n",
    "#Damit wir zwei Bilder pro Klasse haben, iterieren wir durch das Validierungsset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Ziel: Zwei Bilder pro Klasse (z.‚ÄØB. 'Apple___healthy', 'Tomato___Early_blight', ‚Ä¶)\n",
    "images_by_class = defaultdict(list)\n",
    "\n",
    "# Iteriere durch das gesamte Validierungsset\n",
    "for images, labels in dataset_valid:\n",
    "    for img, label in zip(images, labels):\n",
    "        label_int = int(label.numpy())\n",
    "        if len(images_by_class[label_int]) < 2:\n",
    "            images_by_class[label_int].append(img.numpy())\n",
    "        # Abbruchbedingung: wenn alle Klassen 2 Bilder haben\n",
    "        if all(len(v) >= 2 for v in images_by_class.values()):\n",
    "            break\n",
    "    if all(len(v) >= 2 for v in images_by_class.values()):\n",
    "        break\n",
    "\n",
    "# Jetzt alle gesammelten Bilder & Labels extrahieren\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for label, imgs in images_by_class.items():\n",
    "    all_images.extend(imgs)\n",
    "    all_labels.extend([label] * len(imgs))\n",
    "\n",
    "# In Arrays umwandeln\n",
    "all_images = np.array(all_images).astype(np.uint8)\n",
    "all_labels = np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_grad_cam_cnn(images, model)\n",
    "#save_path = r\"C:\\Users\\Alex\\Documents\\GitHub\\may25_bds_plants\\04_src\\images_grad_cam\\first_model_2025_07_29\"\n",
    "save_path = \n",
    "#show_grad_cam_cnn(images, labels, model, class_names, save_dir=save_path) #f√ºr 4 bilder \n",
    "\n",
    "show_grad_cam_cnn(all_images, all_labels, model, class_names, save_dir=save_path) #f√ºr alle bilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7cca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "def explain_and_save_overlay_per_class(\n",
    "    model,\n",
    "    dataset,                 # tf.data.Dataset\n",
    "    class_names,\n",
    "    save_dir,\n",
    "    max_evals=500,\n",
    "    samples_per_class=2\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Bilder pro Klasse sammeln\n",
    "    collected = defaultdict(list)\n",
    "\n",
    "    for image, label in dataset.unbatch():\n",
    "        label_index = int(label.numpy())\n",
    "        if len(collected[label_index]) < samples_per_class:\n",
    "            collected[label_index].append(image.numpy())\n",
    "        # Stop early if all classes are full\n",
    "        if all(len(v) >= samples_per_class for v in collected.values()):\n",
    "            break\n",
    "\n",
    "    # Pro Klasse SHAP generieren\n",
    "    for class_index, images in collected.items():\n",
    "        class_name = class_names[class_index]\n",
    "        images = np.stack(images, axis=0)\n",
    "\n",
    "        print(f\"\\nüîç Klasse: {class_name} | Anzahl Bilder: {len(images)}\")\n",
    "\n",
    "        # SHAP-Erkl√§rer\n",
    "        masker = shap.maskers.Image(\"inpaint_telea\", images[0].shape)\n",
    "        explainer = shap.Explainer(model, masker, output_names=class_names)\n",
    "\n",
    "        shap_values = explainer(\n",
    "            images,\n",
    "            max_evals=max_evals,\n",
    "            outputs=shap.Explanation.argsort.flip[:1]\n",
    "        )\n",
    "\n",
    "        for i, shap_exp in enumerate(shap_values):\n",
    "            img = images[i]\n",
    "\n",
    "            shap_val = shap_exp.values\n",
    "            if isinstance(shap_val, list):\n",
    "                shap_val = shap_val[0]\n",
    "\n",
    "            while shap_val.ndim > 3:\n",
    "                shap_val = np.squeeze(shap_val, axis=-1)\n",
    "\n",
    "            if shap_val.shape != img.shape:\n",
    "                print(f\"‚ùå Shape mismatch: {shap_val.shape} vs {img.shape}\")\n",
    "                continue\n",
    "\n",
    "            # SHAP-Karte mitteln (H, W)\n",
    "            shap_overlay = shap_val.mean(axis=-1)\n",
    "\n",
    "            # Normalisieren\n",
    "            shap_norm = (shap_overlay - shap_overlay.min()) / (shap_overlay.ptp() + 1e-8)\n",
    "            cmap = plt.get_cmap(\"bwr\")\n",
    "            heatmap = cmap(shap_norm)[:, :, :3]\n",
    "\n",
    "            img_float = img.astype(np.float32) / 255.0\n",
    "            overlay = (0.6 * img_float + 0.4 * heatmap).clip(0, 1)\n",
    "\n",
    "            # Speichern\n",
    "            safe_class_name = class_name.replace('/', '_').replace(' ', '_')\n",
    "            overlay_path = os.path.join(save_dir, f\"{safe_class_name}_img{i+1}_overlay.png\")\n",
    "            original_path = os.path.join(save_dir, f\"{safe_class_name}_img{i+1}_original.png\")\n",
    "\n",
    "            Image.fromarray((overlay * 255).astype(np.uint8)).save(overlay_path)\n",
    "            Image.fromarray(img.astype(np.uint8)).save(original_path)\n",
    "\n",
    "            print(f\"‚úÖ Gespeichert: {overlay_path}\")\n",
    "            print(f\"‚úÖ Gespeichert: {original_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e271403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path_shap = r\"C:\\Users\\Alex\\Documents\\GitHub\\may25_bds_plants\\04_src\\images_shap\\first_model_2025_07_29\"\n",
    "save_path_shap = \n",
    "\n",
    "\n",
    "explain_and_save_overlay_per_class(\n",
    "    model=model,\n",
    "    dataset=dataset_valid,\n",
    "    class_names=class_names,\n",
    "    save_dir=save_path_shap,\n",
    "    max_evals=500,\n",
    "    samples_per_class=2  # 2 Bilder pro Klasse\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
